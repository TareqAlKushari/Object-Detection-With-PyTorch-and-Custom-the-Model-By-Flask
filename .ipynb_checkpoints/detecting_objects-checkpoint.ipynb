{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49fab0eb-c8cb-4e84-ac83-d033fa228afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection import FasterRCNN_ResNet50_FPN_V2_Weights\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "918eaa6b-74da-43b0-9adc-48c58c99312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "weights = FasterRCNN_ResNet50_FPN_V2_Weights.COCO_V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9783ae12-7bb1-494d-b9f7-0aab472ff70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the torchvision image transforms.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e19892d3-1f83-4c90-8e7d-2456dff55e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__background__',\n",
       " 'person',\n",
       " 'bicycle',\n",
       " 'car',\n",
       " 'motorcycle',\n",
       " 'airplane',\n",
       " 'bus',\n",
       " 'train',\n",
       " 'truck',\n",
       " 'boat',\n",
       " 'traffic light',\n",
       " 'fire hydrant',\n",
       " 'N/A',\n",
       " 'stop sign',\n",
       " 'parking meter',\n",
       " 'bench',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'sheep',\n",
       " 'cow',\n",
       " 'elephant',\n",
       " 'bear',\n",
       " 'zebra',\n",
       " 'giraffe',\n",
       " 'N/A',\n",
       " 'backpack',\n",
       " 'umbrella',\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 'handbag',\n",
       " 'tie',\n",
       " 'suitcase',\n",
       " 'frisbee',\n",
       " 'skis',\n",
       " 'snowboard',\n",
       " 'sports ball',\n",
       " 'kite',\n",
       " 'baseball bat',\n",
       " 'baseball glove',\n",
       " 'skateboard',\n",
       " 'surfboard',\n",
       " 'tennis racket',\n",
       " 'bottle',\n",
       " 'N/A',\n",
       " 'wine glass',\n",
       " 'cup',\n",
       " 'fork',\n",
       " 'knife',\n",
       " 'spoon',\n",
       " 'bowl',\n",
       " 'banana',\n",
       " 'apple',\n",
       " 'sandwich',\n",
       " 'orange',\n",
       " 'broccoli',\n",
       " 'carrot',\n",
       " 'hot dog',\n",
       " 'pizza',\n",
       " 'donut',\n",
       " 'cake',\n",
       " 'chair',\n",
       " 'couch',\n",
       " 'potted plant',\n",
       " 'bed',\n",
       " 'N/A',\n",
       " 'dining table',\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 'toilet',\n",
       " 'N/A',\n",
       " 'tv',\n",
       " 'laptop',\n",
       " 'mouse',\n",
       " 'remote',\n",
       " 'keyboard',\n",
       " 'cell phone',\n",
       " 'microwave',\n",
       " 'oven',\n",
       " 'toaster',\n",
       " 'sink',\n",
       " 'refrigerator',\n",
       " 'N/A',\n",
       " 'book',\n",
       " 'clock',\n",
       " 'vase',\n",
       " 'scissors',\n",
       " 'teddy bear',\n",
       " 'hair drier',\n",
       " 'toothbrush']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " weights.meta[\"categories\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bc239d3-e0bd-4e93-ae73-2ef24c82c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9de75df4-c9fb-4e82-b110-c8d823712b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different colors for each class.\n",
    "COLORS = np.random.uniform(0, 255, size=(len(COCO_INSTANCE_CATEGORY_NAMES), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a74bdc2-95b9-4d90-a943-65f0c89f40bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(device='cpu'):\n",
    "    # Load the model.\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(weights=weights)\n",
    "    \n",
    "    # Load the model onto the computation device.\n",
    "    model = model.eval().to(device)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "696cf47f-eb34-4152-9485-e6fcc8548464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image, model, device, detection_threshold):\n",
    "    \"\"\"\n",
    "    Predict the output of an image after forward pass through\n",
    "    the model and return the bounding boxes, class names, and \n",
    "    class labels. \n",
    "    \"\"\"\n",
    "    # Transform the image to tensor.\n",
    "    image = transform(image).to(device)\n",
    "    # Add a batch dimension.\n",
    "    image = image.unsqueeze(0) \n",
    "    # Get the predictions on the image.\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image) \n",
    "\n",
    "    # Get score for all the predicted objects.\n",
    "    pred_scores = outputs[0]['scores'].detach().cpu().numpy()\n",
    "\n",
    "    # Get all the predicted bounding boxes.\n",
    "    pred_bboxes = outputs[0]['boxes'].detach().cpu().numpy()\n",
    "    # Get boxes above the threshold score.\n",
    "    boxes = pred_bboxes[pred_scores >= detection_threshold].astype(np.int32)\n",
    "    labels = outputs[0]['labels'][:len(boxes)]\n",
    "    # Get all the predicited class names.\n",
    "    pred_classes = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in labels.cpu().numpy()]\n",
    "\n",
    "    return boxes, pred_classes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5d28d00-ac5c-46d1-8639-a7db2721d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(boxes, classes, labels, image):\n",
    "    \"\"\"\n",
    "    Draws the bounding box around a detected object.\n",
    "    \"\"\"\n",
    "    lw = max(round(sum(image.shape) / 2 * 0.003), 2)  # Line width.\n",
    "    tf = max(lw - 1, 1) # Font thickness.\n",
    "\n",
    "    for i, box in enumerate(boxes):\n",
    "        color = COLORS[labels[i]]\n",
    "        cv2.rectangle(\n",
    "            img=image,\n",
    "            pt1=(int(box[0]), int(box[1])),\n",
    "            pt2=(int(box[2]), int(box[3])),\n",
    "            color=color[::-1], \n",
    "            thickness=lw\n",
    "        )\n",
    "        cv2.putText(\n",
    "            img=image, \n",
    "            text=classes[i], \n",
    "            org=(int(box[0]), int(box[1]-5)),\n",
    "            fontFace=cv2.FONT_HERSHEY_SIMPLEX, \n",
    "            fontScale=lw / 3, \n",
    "            color=color[::-1], \n",
    "            thickness=tf, \n",
    "            lineType=cv2.LINE_AA\n",
    "        )\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb6a46ee-4ce9-4db5-8e28-e797f84b2064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectImage(input, threshold=0.5):\n",
    "    # Define the computation device.\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = get_model(device)\n",
    "    \n",
    "    # Read the image.\n",
    "    image = Image.open(input).convert('RGB')\n",
    "    # Create a BGR copy of the image for annotation.\n",
    "    image_bgr = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "    # Detect outputs.\n",
    "    with torch.no_grad():\n",
    "        boxes, classes, labels = predict(image, model, device, threshold)\n",
    "    # Draw bounding boxes.\n",
    "    image = draw_boxes(boxes, classes, labels, image_bgr)\n",
    "    save_name = f\"{input.split('/')[-1].split('.')[0]}_t{''.join(str(threshold).split('.'))}\"\n",
    "    cv2.imshow('Image', image)\n",
    "    cv2.imwrite(f\"outputs/{save_name}.jpg\", image)\n",
    "    cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b39e47b1-6676-4fff-9caa-45206642e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectVideo(input, threshold=0.5):\n",
    "    # Define the computation device.\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = get_model(device)\n",
    "    \n",
    "    cap = cv2.VideoCapture(input)\n",
    "    \n",
    "    if (cap.isOpened() == False):\n",
    "        print('Error while trying to read video. Please check path again')\n",
    "    \n",
    "    # Get the frame width and height.\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    \n",
    "    save_name = f\"{input.split('/')[-1].split('.')[0]}_t{''.join(str(threshold).split('.'))}\"\n",
    "    # Define codec and create VideoWriter object .\n",
    "    out = cv2.VideoWriter(f\"outputs/{save_name}.mp4\", \n",
    "                          cv2.VideoWriter_fourcc(*'mp4v'), 30, \n",
    "                          (frame_width, frame_height))\n",
    "    \n",
    "    frame_count = 0 # To count total frames.\n",
    "    total_fps = 0 # To get the final frames per second.\n",
    "    \n",
    "    # Read until end of video.\n",
    "    while(cap.isOpened):\n",
    "        # Capture each frame of the video.\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame_copy = frame.copy()\n",
    "            frame_copy = cv2.cvtColor(frame_copy, cv2.COLOR_BGR2RGB)\n",
    "            # Get the start time.\n",
    "            start_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                # Get predictions for the current frame.\n",
    "                boxes, classes, labels = predict(\n",
    "                    frame, model, \n",
    "                    device, threshold\n",
    "                )\n",
    "            \n",
    "            # Draw boxes and show current frame on screen.\n",
    "            image = draw_boxes(boxes, classes, labels, frame)\n",
    "    \n",
    "            # Get the end time.\n",
    "            end_time = time.time()\n",
    "            # Get the fps.\n",
    "            fps = 1 / (end_time - start_time)\n",
    "            # Add fps to total fps.\n",
    "            total_fps += fps\n",
    "            # Increment frame count.\n",
    "            frame_count += 1\n",
    "            # Write the FPS on the current frame.\n",
    "            cv2.putText(\n",
    "                img=image, \n",
    "                text=f\"{fps:.3f} FPS\", \n",
    "                org=(15, 30), \n",
    "                fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale=1, \n",
    "                color=(0, 255, 0), \n",
    "                thickness=2,\n",
    "                lineType=cv2.LINE_AA\n",
    "    \n",
    "            )\n",
    "            # Convert from BGR to RGB color format.\n",
    "            cv2.imshow('image', image)\n",
    "            out.write(image)\n",
    "            # Press `q` to exit.\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    \n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # Release VideoCapture().\n",
    "    cap.release()\n",
    "    # Close all frames and video windows.\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Calculate and print the average FPS.\n",
    "    avg_fps = total_fps / frame_count\n",
    "    print(f\"Average FPS: {avg_fps:.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76fce31e-c7a8-41b9-b060-54706b43db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_model(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45ee0b05-3107-4b04-9fe3-cc217935732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \"fasterrcnn_resnet50_model.pt\")\n",
    "# torch.save(model.state_dict(), \"fasterrcnn_resnet50_model_state.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7be8faf7-cd35-46f4-8edb-2f7235160780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_load = torch.load(\"conv_ant_bee_model2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c5ac57-673a-4549-b6d8-f2f8c8405e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d759b51-0d0b-47c0-aa9e-cf4d01212034",
   "metadata": {},
   "outputs": [],
   "source": [
    "detectImage(\"input/image_2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95dcea25-42fa-4aac-b802-ca47d35d8c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average FPS: 4.907\n"
     ]
    }
   ],
   "source": [
    "detectVideo(\"input/video_2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0d743b-026c-4f46-89dc-b0d2c43f3794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad6aef8-280d-4170-8441-df05f62beac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee13dd4-1900-4a65-a6bb-7bf5efac384d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a5bff5b-4b43-43b4-a9c3-8002f8ed7d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python detect_image.py --input input/image_1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f7f2ce2-0fc4-4fbf-88de-c2752bee9a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python detect_image.py --input input/image_2.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f675ff3-f066-4dec-8388-ee80fbf64e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average FPS: 4.785\n"
     ]
    }
   ],
   "source": [
    "# !python detect_video.py --input input/video_1.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89966e15-29d5-436d-bd66-5ad4b929d0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22c077e-0b44-4fc5-a6c0-94750ea66f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python detect_image.py --input data/coco/val2017/000000057782.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93c72e85-729c-4efd-a298-3212bb479d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python detect_image.py --input data/coco/val2017/000000045084.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9930a435-9a06-47b6-bf91-38e6f0b9e92b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85300718-6371-4ea9-8164-68b1a16f2e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8615a31-1186-4ee4-b5c0-fef36a582af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5306a4a5-e7a1-4634-9124-6fda112eeaed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4fad97-9985-4d34-ac19-ff6d86b48cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a594bc-005f-4b1f-8b42-cd90e073fcb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
